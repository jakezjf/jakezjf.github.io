
---
layout:     post
title:      "机器学习之k-近邻算法"
subtitle:   "学习 k-近邻算法 "
date:       2017-03-30
author:     "JianFeng"
header-img: ""
catalog: true
tags:
    - 机器学习
---

> 学习 机器学习之k-近邻算法


# 机器学习之k-近邻算法

最近看了下机器学习的一些算法，做一些记录，本篇介绍一下 **k-近邻算法** ！

# 什么是k-近邻算法

k-近邻算法从字面上就是从数据集合中选取与指定元素相近(距离)的k个元素，然后根据这k个元素的分类情况确定需要预测元素的分类。该算法主要涉及三个要素：

- 训练集

	训练集的数量关系到预测元素分类的准确性
	
- 距离或相似的衡量

	k-近邻算法主要根据距离进行预测
	
- k 值

	k 值确定了我们选择样本数据集中前n个最相似的数据集合，k 通常是不大于 20 的整数
	
通过下图来举个栗子：

![](/img/blog/2017-03-30-ml.jpg)

图中绿色的点是我们要预测的点的分类，实线和虚线分别表示 k 值为3和5的情况，如果 k 值为3，那么绿色点属于红色三角分类的概率为2/3，属于蓝色方块分类的概率为1/3；如果 k 值为5，那么绿色点属于蓝色方块分类的概率为3/5，属于红色三角分类的概率为2/5。所以 k 值的大小也影响预测点分类的判断。
	
	
# k-近邻算法的实现

k-近邻算法(k-nearest neighbor classification)的具体实现：


	from numpy import *
	
	
	def createDataSet():
	    # 给出训练数据以及对应的类别
	    group = array([[1.0, 2.0], [1.2, 0.1], [0.1, 1.4], [0.3, 3.5]])
	    labels = ['A', 'A', 'B', 'B']
	    return group, labels
	
	
	# 通过KNN进行分类
	def classify(input, dataSet, label, k):
	    dataSize = dataSet.shape[0]
	    # 计算欧式距离
	    diff = tile(input, (dataSize, 1)) - dataSet
	    # 算x和y的平方
	    sqdiff = diff ** 2
	    # 行向量分别相加，从而得到新的一个行向量
	    squareDist = sum(sqdiff, axis=1)
	    # x^2 + y^2 开平方得到距离
	    dist = squareDist ** 0.5
	    # 对距离进行排序
	    # argsort()根据元素的值从大到小对元素进行排序，返回下标
	    sortedDistIndex = argsort(dist)
	    classCount = {}
	    for i in range(k):
	        voteLabel = label[sortedDistIndex[i]]
	        print(voteLabel)
	        # 对选取的K个样本所属的类别个数进行统计
	        classCount[voteLabel] = classCount.get(voteLabel, 0) + 1
	    # 选取出现的类别次数最多的类别
	    maxCount = 0
	    for key, value in classCount.items():
	        if value > maxCount:
	            maxCount = value
	            classes = key
	
	    return classes
	
	if __name__ == '__main__':
	    dataSet, labels = createDataSet()
	    input = array([0.3, 3])
	    K = 3
	    output = classify(input, dataSet, labels, K)
	    print("测试数据为:", input, "分类结果为：", output)
	    
	    
	    
	    
	    
	    
	    